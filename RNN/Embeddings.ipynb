{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e49641e"
      },
      "source": [
        "### Import necessary library\n",
        "This cell imports the `one_hot` function from `tensorflow.keras.preprocessing.text` for text tokenization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31357cff"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa93087c"
      },
      "source": [
        "### Define sample sentences\n",
        "This cell defines a list of sample sentences that will be used for demonstration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45c615aa"
      },
      "source": [
        "### sentences\n",
        "sent=[  'the glass of milk',\n",
        "     'the glass of juice',\n",
        "     'the cup of tea',\n",
        "    'I am a good boy',\n",
        "     'I am a good developer',\n",
        "     'understand the meaning of words',\n",
        "     'your videos are good',]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ddac992"
      },
      "source": [
        "### Display sentences\n",
        "This cell displays the list of sample sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69c13d22",
        "outputId": "90996682-6f5e-4a6f-97b9-7f0b61b6b333"
      },
      "source": [
        "sent"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the glass of milk',\n",
              " 'the glass of juice',\n",
              " 'the cup of tea',\n",
              " 'I am a good boy',\n",
              " 'I am a good developer',\n",
              " 'understand the meaning of words',\n",
              " 'your videos are good']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d282f17f"
      },
      "source": [
        "### Define vocabulary size\n",
        "This cell sets the size of the vocabulary for one-hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50248d4d"
      },
      "source": [
        "## Define the vocabulary size\n",
        "voc_size=10000"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83e67a87"
      },
      "source": [
        "### One-Hot Representation\n",
        "This cell applies one-hot encoding to each sentence using the defined vocabulary size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9cfd8e6",
        "outputId": "7f45f94c-d95b-432c-ea91-a5f8c289aa39"
      },
      "source": [
        "### One Hot Representation\n",
        "one_hot_repr = [ one_hot(words,voc_size)for words in sent ]\n",
        "one_hot_repr"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1550, 1497, 2996, 885],\n",
              " [1550, 1497, 2996, 2824],\n",
              " [1550, 6966, 2996, 1121],\n",
              " [61, 4541, 5236, 119, 9764],\n",
              " [61, 4541, 5236, 119, 1648],\n",
              " [6862, 1550, 2850, 2996, 1348],\n",
              " [8032, 8488, 9103, 119]]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69104143"
      },
      "source": [
        "### Import libraries for Word Embedding\n",
        "This cell imports necessary layers and models from TensorFlow/Keras for creating a word embedding model, as well as `pad_sequences` for sequence padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43cf04b9"
      },
      "source": [
        "## word Embedding Representation\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67b165e4"
      },
      "source": [
        "### Import NumPy\n",
        "This cell imports the NumPy library, which is commonly used for numerical operations in Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39bc857a"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afdb31e2"
      },
      "source": [
        "### Pad sequences\n",
        "This cell pads the one-hot encoded sequences to a fixed length (`sent_length`) using pre-padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c3a7c27",
        "outputId": "90c34399-c59d-4f41-df87-e1aa7fa09fa3"
      },
      "source": [
        "sent_length = 8\n",
        "embedded_doc = pad_sequences(one_hot_repr,padding='pre',maxlen = sent_length)\n",
        "print(embedded_doc)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0    0 1550 1497 2996  885]\n",
            " [   0    0    0    0 1550 1497 2996 2824]\n",
            " [   0    0    0    0 1550 6966 2996 1121]\n",
            " [   0    0    0   61 4541 5236  119 9764]\n",
            " [   0    0    0   61 4541 5236  119 1648]\n",
            " [   0    0    0 6862 1550 2850 2996 1348]\n",
            " [   0    0    0    0 8032 8488 9103  119]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35142357"
      },
      "source": [
        "### Define embedding dimension\n",
        "This cell defines the dimension of the word embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a855fa37"
      },
      "source": [
        "## feature representation\n",
        "dim=10"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71833f0e"
      },
      "source": [
        "### Create and compile embedding model\n",
        "This cell creates a simple Sequential model with an Embedding layer. The model is compiled with the Adam optimizer and mean squared error loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6cc3b64",
        "outputId": "b6264d7a-2f4f-436d-b1fa-7849bf8f1c66"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(voc_size,10,input_length=sent_length))\n",
        "model.compile('adam','mse')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ace37c25"
      },
      "source": [
        "### Display model summary\n",
        "This cell displays a summary of the created model, showing the layers and parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "62a071fa",
        "outputId": "b0a807f7-aa9c-4ea6-cda3-c02404ae400f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a47e3df"
      },
      "source": [
        "### Predict embeddings for all sentences\n",
        "This cell uses the trained embedding model to predict the embeddings for all the padded sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c109b20",
        "outputId": "3e098e00-adee-403f-cd0d-0121ae7cb087"
      },
      "source": [
        "model.predict(embedded_doc)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [ 0.02327278,  0.01306433, -0.00878923,  0.02516599,\n",
              "         -0.00067272, -0.02039397, -0.00201815,  0.03409041,\n",
              "         -0.02012038, -0.00958437],\n",
              "        [ 0.02557745,  0.02042638, -0.00111772,  0.010258  ,\n",
              "         -0.0157359 , -0.0293309 ,  0.00081437,  0.0274283 ,\n",
              "         -0.04709252,  0.01201929],\n",
              "        [ 0.01957877, -0.03016071, -0.03244666, -0.00611923,\n",
              "         -0.02882701, -0.00708292, -0.04256118, -0.03936535,\n",
              "          0.01484424, -0.01587363],\n",
              "        [ 0.03878618,  0.00601629, -0.00324152,  0.01182431,\n",
              "          0.03492622, -0.03111096, -0.04133754,  0.0379251 ,\n",
              "          0.0203384 , -0.03282344]],\n",
              "\n",
              "       [[-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [ 0.02327278,  0.01306433, -0.00878923,  0.02516599,\n",
              "         -0.00067272, -0.02039397, -0.00201815,  0.03409041,\n",
              "         -0.02012038, -0.00958437],\n",
              "        [ 0.02557745,  0.02042638, -0.00111772,  0.010258  ,\n",
              "         -0.0157359 , -0.0293309 ,  0.00081437,  0.0274283 ,\n",
              "         -0.04709252,  0.01201929],\n",
              "        [ 0.01957877, -0.03016071, -0.03244666, -0.00611923,\n",
              "         -0.02882701, -0.00708292, -0.04256118, -0.03936535,\n",
              "          0.01484424, -0.01587363],\n",
              "        [-0.00613315,  0.00355632, -0.02785352, -0.0248113 ,\n",
              "          0.04283761, -0.00192579,  0.02582637, -0.01775774,\n",
              "          0.0319113 , -0.01713013]],\n",
              "\n",
              "       [[-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [ 0.02327278,  0.01306433, -0.00878923,  0.02516599,\n",
              "         -0.00067272, -0.02039397, -0.00201815,  0.03409041,\n",
              "         -0.02012038, -0.00958437],\n",
              "        [-0.00434582,  0.03211529,  0.01999653, -0.00841999,\n",
              "          0.00386062,  0.01736815,  0.04991022, -0.03329045,\n",
              "          0.01941139,  0.01236998],\n",
              "        [ 0.01957877, -0.03016071, -0.03244666, -0.00611923,\n",
              "         -0.02882701, -0.00708292, -0.04256118, -0.03936535,\n",
              "          0.01484424, -0.01587363],\n",
              "        [-0.03710366,  0.03264115, -0.02413263,  0.00976001,\n",
              "         -0.03227147, -0.02255198,  0.02261129, -0.01458253,\n",
              "         -0.00195601,  0.04496708]],\n",
              "\n",
              "       [[-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.02705275,  0.01528827, -0.01556269,  0.03979149,\n",
              "          0.01625153,  0.04819277, -0.03326148,  0.04455302,\n",
              "          0.03718041,  0.04409531],\n",
              "        [-0.04656167, -0.00763392,  0.03074907,  0.03941267,\n",
              "         -0.01470704,  0.00783964, -0.00974578,  0.04238587,\n",
              "         -0.02614604, -0.03565317],\n",
              "        [-0.03655993, -0.00586263, -0.01432421, -0.02851166,\n",
              "         -0.02505568,  0.00420343,  0.03167899,  0.00180916,\n",
              "         -0.04958579,  0.03763087],\n",
              "        [-0.03394598,  0.03442046,  0.02551149,  0.0221296 ,\n",
              "          0.01284638, -0.03068665,  0.04525428, -0.01099422,\n",
              "         -0.00170965, -0.04780463],\n",
              "        [-0.01185173,  0.03421522, -0.02424774,  0.03041071,\n",
              "         -0.02301556,  0.0432942 ,  0.00443425, -0.03052932,\n",
              "         -0.02661854,  0.02057889]],\n",
              "\n",
              "       [[-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.02705275,  0.01528827, -0.01556269,  0.03979149,\n",
              "          0.01625153,  0.04819277, -0.03326148,  0.04455302,\n",
              "          0.03718041,  0.04409531],\n",
              "        [-0.04656167, -0.00763392,  0.03074907,  0.03941267,\n",
              "         -0.01470704,  0.00783964, -0.00974578,  0.04238587,\n",
              "         -0.02614604, -0.03565317],\n",
              "        [-0.03655993, -0.00586263, -0.01432421, -0.02851166,\n",
              "         -0.02505568,  0.00420343,  0.03167899,  0.00180916,\n",
              "         -0.04958579,  0.03763087],\n",
              "        [-0.03394598,  0.03442046,  0.02551149,  0.0221296 ,\n",
              "          0.01284638, -0.03068665,  0.04525428, -0.01099422,\n",
              "         -0.00170965, -0.04780463],\n",
              "        [ 0.0464669 , -0.02819066, -0.02831037, -0.01246276,\n",
              "          0.03702544,  0.00952467,  0.02513114,  0.02328353,\n",
              "          0.0472965 , -0.01133155]],\n",
              "\n",
              "       [[-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [ 0.01423213, -0.02682157, -0.01053513,  0.00137993,\n",
              "         -0.01904711, -0.01972761,  0.04871713, -0.02584085,\n",
              "         -0.04334791,  0.03371776],\n",
              "        [ 0.02327278,  0.01306433, -0.00878923,  0.02516599,\n",
              "         -0.00067272, -0.02039397, -0.00201815,  0.03409041,\n",
              "         -0.02012038, -0.00958437],\n",
              "        [-0.01160039,  0.03277958,  0.02959195, -0.02425781,\n",
              "          0.03817043,  0.04738778,  0.04768031, -0.04615592,\n",
              "          0.00869616, -0.00130571],\n",
              "        [ 0.01957877, -0.03016071, -0.03244666, -0.00611923,\n",
              "         -0.02882701, -0.00708292, -0.04256118, -0.03936535,\n",
              "          0.01484424, -0.01587363],\n",
              "        [ 0.02583355,  0.04744743, -0.03445488,  0.02875126,\n",
              "         -0.0316168 ,  0.02502252, -0.0197093 , -0.03377327,\n",
              "          0.01679578, -0.03487383]],\n",
              "\n",
              "       [[-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.02017364, -0.0154026 , -0.04902538, -0.03715525,\n",
              "          0.00292827,  0.03827718, -0.01009549,  0.03637649,\n",
              "          0.04545866,  0.02230299],\n",
              "        [-0.00929549, -0.03962715, -0.01858824,  0.03254849,\n",
              "          0.01419797, -0.02761716, -0.01021258,  0.02199086,\n",
              "         -0.02863227,  0.00866357],\n",
              "        [ 0.03426334,  0.04444167, -0.02172183,  0.04205332,\n",
              "          0.04997521,  0.04884971, -0.03033925, -0.00941629,\n",
              "          0.02316299,  0.00101138],\n",
              "        [-0.03394598,  0.03442046,  0.02551149,  0.0221296 ,\n",
              "          0.01284638, -0.03068665,  0.04525428, -0.01099422,\n",
              "         -0.00170965, -0.04780463]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f058f484"
      },
      "source": [
        "### Display the first embedded document\n",
        "This cell displays the first padded and embedded sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "497304f1",
        "outputId": "b839e98d-91aa-4823-beba-a306c2dc6923"
      },
      "source": [
        "embedded_doc[0]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0, 1550, 1497, 2996,  885], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55a1db65"
      },
      "source": [
        "### Predict embedding for a single sentence\n",
        "This cell predicts the embedding for the first sentence, ensuring the input has the correct batch dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "852c3b01",
        "outputId": "cbc6a98a-1c36-4e1f-c147-78b86d9c524f"
      },
      "source": [
        "model.predict(np.expand_dims(embedded_doc[0], axis=0))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [-0.00467901, -0.00231373, -0.02180827,  0.01534377,\n",
              "          0.03669937,  0.04962161,  0.03154228,  0.02740307,\n",
              "         -0.03027835,  0.00232493],\n",
              "        [ 0.02327278,  0.01306433, -0.00878923,  0.02516599,\n",
              "         -0.00067272, -0.02039397, -0.00201815,  0.03409041,\n",
              "         -0.02012038, -0.00958437],\n",
              "        [ 0.02557745,  0.02042638, -0.00111772,  0.010258  ,\n",
              "         -0.0157359 , -0.0293309 ,  0.00081437,  0.0274283 ,\n",
              "         -0.04709252,  0.01201929],\n",
              "        [ 0.01957877, -0.03016071, -0.03244666, -0.00611923,\n",
              "         -0.02882701, -0.00708292, -0.04256118, -0.03936535,\n",
              "          0.01484424, -0.01587363],\n",
              "        [ 0.03878618,  0.00601629, -0.00324152,  0.01182431,\n",
              "          0.03492622, -0.03111096, -0.04133754,  0.0379251 ,\n",
              "          0.0203384 , -0.03282344]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}